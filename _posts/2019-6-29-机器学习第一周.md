# 第一周总结

## 先导内容

### 结构化数据 v.s 非结构化数据 v.s 半结构化数据

1. 结构化数据：可以使用关系型数据库表示和存储，表现为二维形式的数据。

2. 非结构化数据：没有固定结构的数据。各种文档、图片、视频/音频等都属于非结构化数据。

3. 半结构化数据：是结构化数据的一种形式，它并不符合关系型数据库或其他数据表的形式关联起来的数据模型结构，但包含相关标记，用来分隔语义元素以及对记录和字段进行分层。

   

### 数据分析流程

数据获取->数据清洗->数据预处理->特征工程->选择机器学习模型->训练->调参->模型部署上线

1. 特征提取

   - 针对图像，可以将其灰度值或者一些相关统计值数据作为其属性值
   - 针对文本，可以将使用词嵌入的方案，将其向量化

2. 处理缺失数据

   - 若缺失率太高，直接丢弃
   - 若数值型数据，则优先考虑使用平均值，中位数填充
   - 若类别型数据，则优先考虑使用众数填充

3. 数据定标

   - 归一化：映射到(0,1)之间
     $$
     x_{n o r m}=\frac{x-x_{\min }}{x_{\max }-x_{\min }}
     $$

   - 标准化：标准到均值为1，方差为0的状态
     $$
     x_{s t d}=\frac{x-\mu}{\sigma}
     $$

4. 数据转换: One-Hot encoding, One/Two/MultiGram, Bag of words, 取对数 

## KNN

### 核心思想

给定的数据集，对一个新输入的实例，在训练数据集中找到与该实例最相近的K的实例，这K个实例的多数属于某个类，就把该输入实例分类到这个类中。

### 需要考虑的问题

1. 为什么K总是取奇数（1，3，5...）?

   在为新实例选择多数类时，需要找到前K个中的多数类，此时需要投票法

2. K的选取对决策边界的影响？

   K越小，分类边界曲线越光滑，偏差越小，方差越大；K越大，分类边界曲线越平坦，偏差越大，方差越小。

3. 怎样选择合适的K呢？

   使用交叉验证：交叉验证可以用来1）综合评估模型的优劣；2）选择超参数

4. 当有一个属性值取值范围相较于其他属性值偏大时，则会有什么影响？

   由于KNN是采用的距离计算，所以，当在某一个维度（属性值）上取值范围过大时，该维度对最后的距离值取决定性因素，其他维度的距离值所产生的效果微乎其微。为解决这个问题，要对数据集进行归一化/标准化操作。
